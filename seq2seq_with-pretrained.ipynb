{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alesnim/chat_seq/blob/master/seq2seq_with-pretrained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "bex4SYnKMbAq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import nltk\n",
        "import itertools\n",
        "import operator\n",
        "import pickle\n",
        "import numpy as np    \n",
        "from keras.preprocessing import sequence\n",
        "from scipy import sparse, io\n",
        "from numpy.random import permutation\n",
        "import re\n",
        "import gensim\n",
        "\n",
        "path_vec = './gdrive/My Drive/all.norm-sz100-w10-cb0-it1-min100.w2v'\n",
        "\n",
        "embb = gensim.models.KeyedVectors.load_word2vec_format(path_vec, binary=True, unicode_errors='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvKrvCDwM75A",
        "colab_type": "code",
        "outputId": "df5acc4d-0559-40f0-937a-61ebcd0b0f26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "67O-8a2pr8Fa",
        "colab_type": "code",
        "outputId": "fae204ad-33ff-4751-edf2-13a3f13a6ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(1234)  # for reproducibility\n",
        "import pandas as pd\n",
        "import os\n",
        "import csv\n",
        "import nltk\n",
        "import itertools\n",
        "import operator\n",
        "import pickle\n",
        "import numpy as np    \n",
        "from keras.preprocessing import sequence\n",
        "from scipy import sparse, io\n",
        "from numpy.random import permutation\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHwgm0CMtNmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "text = open('./gdrive/My Drive/full_raw.txt', 'r').readlines()\n",
        "q = open('./gdrive/My Drive/context.txt', 'w')\n",
        "a = open('./gdrive/My Drive/answers.txt', 'w')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Ud5lgcZuyYt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gkasi3aet5dX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i, raw_word in enumerate(text):\n",
        "  if i % 2 == 0:\n",
        "    q.write(raw_word)\n",
        "  else:\n",
        "    a.write(raw_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Rt0LH49vIxv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q.close()\n",
        "a.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VlF5diGgvY1e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_1WbOm5r745",
        "colab_type": "code",
        "outputId": "6ccd2560-fc04-45c8-aa6a-b05c4869e28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "questions_file = './gdrive/My Drive/context.txt'\n",
        "answers_file = './gdrive/My Drive/answers.txt'\n",
        "vocabulary_file = './gdrive/My Drive/vocabulary_from_raw.txt'\n",
        "padded_questions_file = './gdrive/My Drive/Padded_context.txt'\n",
        "padded_answers_file = './gdrive/My Drive/Padded_answers.txt'\n",
        "unknown_token = 'something'\n",
        "\n",
        "vocabulary_size = 7000\n",
        "max_features = vocabulary_size\n",
        "maxlen_input = 50\n",
        "maxlen_output = 50  # cut texts after this number of words\n",
        "\n",
        "print (\"Reading the context data...\")\n",
        "q = open(questions_file, 'r')\n",
        "questions = q.read()\n",
        "print (\"Reading the answer data...\")\n",
        "a = open(answers_file, 'r')\n",
        "answers = a.read()\n",
        "all = answers + questions\n",
        "print (\"Tokenazing the answers...\")\n",
        "paragraphs_a = [p for p in answers.split('\\n')]\n",
        "paragraphs_b = [p for p in all.split('\\n')]\n",
        "paragraphs_a = ['start '+p+' end' for p in paragraphs_a]\n",
        "paragraphs_b = ['start '+p+' end' for p in paragraphs_b]\n",
        "paragraphs_b = ' '.join(paragraphs_b)\n",
        "tokenized_text = paragraphs_b.split()\n",
        "paragraphs_q = [p for p in questions.split('\\n') ]\n",
        "tokenized_answers = [p.split() for p in paragraphs_a]\n",
        "tokenized_questions = [p.split() for p in paragraphs_q]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading the context data...\n",
            "Reading the answer data...\n",
            "Tokenazing the answers...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yFOGsQLMr72S",
        "colab_type": "code",
        "outputId": "33dceac6-ce45-43d5-9367-7eb586bb972d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "### Counting the word frequencies:\n",
        "word_freq = nltk.FreqDist(itertools.chain(tokenized_text))\n",
        "print (\"Found %d unique words tokens.\" % len(word_freq.items()))\n",
        "##\n",
        "### Getting the most common words and build index_to_word and word_to_index vectors:\n",
        "vocab = word_freq.most_common(vocabulary_size-1)\n",
        "##\n",
        "### Saving vocabulary:\n",
        "with open(vocabulary_file, 'wb') as v:\n",
        "  pickle.dump(vocab, v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 48516 unique words tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WyPFnrspr7sB",
        "colab_type": "code",
        "outputId": "fb4aab54-973e-4cc1-f421-4d235fd8aa96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab[6000]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('машинами', 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "-ZZRw3K7r7go",
        "colab_type": "code",
        "outputId": "861738a0-cfe1-4170-ebc3-5588f7eb2459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "index_to_word = [x[0] for x in vocab]\n",
        "index_to_word.append(unknown_token)\n",
        "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
        "\n",
        "print (\"Using vocabulary of size %d.\" % vocabulary_size)\n",
        "print (\"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], \n",
        "                                                                                     vocab[-1][1]))\n",
        "\n",
        "# Replacing all words not in our vocabulary with the unknown token:\n",
        "for i, sent in enumerate(tokenized_answers):\n",
        "    tokenized_answers[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
        "   \n",
        "\n",
        "\n",
        "  \n",
        "for i, sent in enumerate(tokenized_questions):\n",
        "    tokenized_questions[i] = [w if w in word_to_index else unknown_token for w in sent]\n",
        "\n",
        "# Creating the training data:\n",
        "X = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_questions])\n",
        "Y = np.asarray([[word_to_index[w] for w in sent] for sent in tokenized_answers])\n",
        "\n",
        "Q = sequence.pad_sequences(X, maxlen=maxlen_input)\n",
        "A = sequence.pad_sequences(Y, maxlen=maxlen_output, padding='post')\n",
        "\n",
        "with open(padded_questions_file, 'wb') as q:\n",
        "    pickle.dump(Q, q)\n",
        "    \n",
        "with open(padded_answers_file, 'wb') as a:\n",
        "    pickle.dump(A, a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using vocabulary of size 7000.\n",
            "The least frequent word in our vocabulary is 'сходить' and appeared 6 times.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tEe4Tb3kr7V1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Embedding, LSTM, Dense, RepeatVector, Bidirectional, Dropout, merge\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "word_embedding_size = 100\n",
        "sentence_embedding_size = 300\n",
        "dictionary_size = 7000\n",
        "maxlen_input = 50\n",
        "maxlen_output = 50\n",
        "num_subsets = 1\n",
        "Epochs = 100\n",
        "BatchSize = 128  #  Check the capacity of your GPU\n",
        "Patience = 0\n",
        "dropout = .25\n",
        "n_test = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3vYTe-_5lx4p",
        "colab_type": "code",
        "outputId": "bd58519e-d737-4181-8281-1b1fea057301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "! wget https://rusvectores.org/static/models/rusvectores4/fasttext/araneum_none_fasttextskipgram_300_5_2018.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-24 10:46:04--  https://rusvectores.org/static/models/rusvectores4/fasttext/araneum_none_fasttextskipgram_300_5_2018.tgz\n",
            "Resolving rusvectores.org (rusvectores.org)... 176.195.79.50\n",
            "Connecting to rusvectores.org (rusvectores.org)|176.195.79.50|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 707427878 (675M) [application/x-gzip]\n",
            "Saving to: ‘araneum_none_fasttextskipgram_300_5_2018.tgz’\n",
            "\n",
            "araneum_none_fastte 100%[===================>] 674.66M  5.55MB/s    in 2m 4s   \n",
            "\n",
            "2018-12-24 10:48:09 (5.43 MB/s) - ‘araneum_none_fasttextskipgram_300_5_2018.tgz’ saved [707427878/707427878]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dguipg9F1YgY",
        "colab_type": "code",
        "outputId": "37b93863-0eba-4844-b24e-9dd64a0322a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "! head ./glove.6B.100d.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "head: cannot open './glove.6B.100d.txt' for reading: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JSOLNFbT4Xi5",
        "colab_type": "code",
        "outputId": "8386a609-89d8-4902-d061-282a31ffd712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "sdfdsfasdff = [1,1,1,1,1,1,1]\n",
        "str(sdfdsfasdff)\n",
        "type(sdfdsfasdff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "4WsHO_XU1ojD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "path_vec = './gdrive/My Drive/all.norm-sz100-w10-cb0-it1-min100.w2v'\n",
        "\n",
        "embb = gensim.models.KeyedVectors.load_word2vec_format(path_vec, binary=True, \n",
        "                                                       unicode_errors='ignore')\n",
        "with open('./gdrive/My Drive/word2vec.100.txt', 'w') as f:\n",
        "  for _,word in enumerate(embb.vocab):\n",
        "    line = ''\n",
        "    line = word\n",
        "    vector = embb.get_vector(word)\n",
        "    vector_str = ' '\n",
        "    for num in vector:\n",
        "      vector_str.join(' ' + str(num))\n",
        "    f.write(line + ' ' + vector_str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GDqwx--i3jRQ",
        "colab_type": "code",
        "outputId": "63a4c2ff-3b0c-4763-e25c-010a62b6da28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "! wget https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ru.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-24 12:00:26--  https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ru.300.vec.gz\n",
            "Resolving s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)... 52.219.20.21\n",
            "Connecting to s3-us-west-1.amazonaws.com (s3-us-west-1.amazonaws.com)|52.219.20.21|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  36.2MB/s    in 32s     \n",
            "\n",
            "2018-12-24 12:00:58 (39.3 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0w-Aoy7y9VZD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "! gunzip ./cc.ru.300.vec.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "smBIqK69GSTf",
        "colab_type": "code",
        "outputId": "864ea6d0-bd31-4867-9523-25a2c520b216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "! head ./cc.ru.300.vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2000000 300\n",
            ", -0.0326 -0.1499 0.0232 0.0029 -0.0709 -0.0078 -0.0751 -0.0190 -0.0197 -0.0015 0.1447 0.4037 0.0650 -0.0183 0.0353 -0.0157 0.0130 -0.0376 0.0386 0.0096 -0.0644 0.2843 -0.0720 0.0322 -0.0135 -0.0217 0.1510 0.0431 -0.0017 0.0021 0.0285 -0.0526 0.0079 -0.0050 0.0025 -0.0294 -0.1391 -1.1404 -0.3228 -0.0796 0.0221 0.0347 0.0124 -0.1609 -0.1860 0.1010 -0.0072 0.0562 0.0104 0.0879 0.0207 0.0001 0.0189 0.0232 -0.0212 -0.1040 -0.0341 -0.0033 -0.2091 0.0981 -0.4552 -0.1114 0.0309 0.0974 -0.1251 0.0788 -0.1059 -0.0393 -0.0023 -0.0597 -0.1107 0.0122 -0.0025 0.0319 -0.1282 -0.0260 -0.0666 0.0950 0.0201 0.0387 0.0137 0.1422 -0.0038 -0.0242 0.0055 -0.1737 0.1817 0.0828 -0.0963 0.0215 0.0611 0.0505 -0.0185 -0.0197 0.0769 0.0172 0.0435 0.0718 -0.3437 0.0018 -0.0690 0.0055 -0.0850 -0.0049 0.0581 0.0275 -0.0969 0.0155 -0.0914 -0.0026 -0.0026 -0.0130 0.0385 -0.0297 0.0362 -0.0304 -0.0083 0.0178 -0.0502 0.0323 0.1164 -0.0139 0.0184 0.0551 0.0086 0.0343 -0.0594 -0.0466 -0.1004 -0.0480 0.0045 0.0682 0.0275 0.0459 -0.0715 0.0032 -0.0437 -0.0042 -0.0627 -0.0541 0.0066 -0.0329 -0.0535 0.1856 -0.0051 0.1174 0.3832 0.1797 -0.0561 0.0526 -0.2077 0.0188 -0.0433 -0.0362 -0.0215 0.0336 -0.0103 -0.1472 -0.0937 0.0171 -0.0881 -0.0423 0.0864 -0.0248 0.0308 -0.0459 0.0867 0.0690 -0.0180 0.0883 -0.1114 0.0651 0.0241 -0.0119 -0.2114 0.0308 0.0460 -0.1006 0.2630 0.0512 -0.1440 -0.5553 0.0091 -0.0750 0.0192 0.0409 -0.0524 0.0265 -0.0869 -0.0284 0.0346 0.0433 -0.0328 -0.0006 0.1074 -0.0284 0.1935 0.1173 -0.0038 -0.0828 0.0574 0.0598 0.0382 -0.0118 0.0040 -0.0304 -0.0769 -0.0005 0.0425 0.0556 -0.3237 -0.0188 0.0865 0.0696 -0.0518 0.0590 0.0148 0.1851 0.0732 0.0087 0.0627 -0.0547 -0.0086 -0.0147 -0.0928 -0.0067 0.0449 0.0512 0.0075 -0.1351 0.1588 0.2211 -0.0342 -0.1996 -0.1263 -0.1266 0.0056 0.0287 0.0401 -0.0185 0.0428 -0.0019 -0.0132 -0.0102 0.0057 -0.0359 -0.0048 0.0008 -0.0342 -0.0379 0.0665 0.0594 -0.0296 -0.0665 -0.0497 0.1147 0.0181 -0.0468 0.0516 0.1494 -0.1153 -0.0312 -0.1671 -0.0240 0.0513 0.1395 0.0791 -0.0186 -0.0505 -0.0109 0.0998 -0.0451 0.4404 -0.0103 -0.0244 0.0809 -0.0338 0.0281 0.0353 0.0514 0.1603 0.0299 0.0717 0.0274 -0.0551 -0.0244 0.0896 0.1202 0.0313 -0.0337 -0.0679 -0.0482 0.0013 -0.0308 -0.0185 -0.0418 -0.0030 -0.0237 -0.0261 -0.1832\n",
            ". -0.0555 -0.0175 0.0936 0.0245 -0.0708 0.0449 0.0289 0.0999 -0.0061 -0.1266 0.0646 -0.1619 0.1348 -0.0350 0.0029 -0.0831 -0.0197 0.0955 0.0265 -0.0714 0.0450 -0.1974 0.0187 -0.0025 -0.0285 -0.0557 -0.0006 0.0926 0.0065 0.0026 -0.1561 -0.0522 -0.0052 0.1444 -0.0155 0.0779 -0.0944 -1.0973 0.0712 0.0024 0.0195 -0.1338 0.0031 0.0222 -0.1216 -0.0024 -0.0709 -0.0246 -0.0926 -0.1463 -0.0202 -0.0516 -0.0496 0.1352 0.0796 -0.0747 0.0176 0.1194 -0.1695 0.0480 -0.5960 -0.0854 0.1016 -0.0136 -0.0296 -0.0213 0.0440 0.0895 -0.0049 -0.0577 0.0078 -0.0445 0.1137 0.0251 0.0004 0.0747 0.0025 -0.0312 0.1509 0.0563 0.0219 0.0240 0.3030 0.0631 -0.0720 -0.1112 0.2372 -0.0381 -0.0333 -0.0524 -0.1644 0.0568 -0.0433 -0.2003 -0.0190 0.0376 -0.0652 0.0200 0.3984 -0.0516 -0.0046 -0.3912 -0.0620 0.0273 0.0326 0.0087 -0.3696 0.0236 -0.0865 -0.0007 0.0480 0.0372 0.1328 -0.0126 0.0096 -0.1028 -0.0055 0.2011 -0.0773 -0.0477 0.0451 0.0595 0.1450 -0.0010 0.0485 0.0082 -0.0395 -0.1651 0.0152 -0.0710 0.0071 0.0816 0.0641 -0.0441 -0.0359 -0.0075 -0.2210 -0.0387 -0.2340 -0.0087 -0.0163 -0.0997 0.0967 0.1947 -0.2136 -0.0091 0.2291 0.3298 0.0298 -0.0793 0.0429 -0.0320 0.2735 0.0537 0.0602 0.0350 -0.0088 -0.0392 -0.1605 -0.1284 -0.0152 0.0597 0.0812 0.0076 0.0759 -0.1167 0.0569 0.0186 -0.0069 0.0864 -0.0345 0.0149 -0.0391 -0.1386 -0.4852 -0.0624 -0.1267 0.0485 0.0834 0.0195 -0.0169 -0.1302 -0.0185 -0.0021 -0.0909 -0.0626 0.0542 0.0719 -0.0238 -0.0705 0.0125 0.0535 0.0110 0.1141 0.0493 0.0116 -0.1063 0.0546 -0.0083 -0.0837 0.0486 -0.0540 0.0445 -0.0511 -0.0734 0.0222 -0.0162 0.0088 -0.0102 0.0264 0.1663 -0.1120 -0.0001 -0.1430 -0.3491 0.0475 -0.0680 -0.0538 0.0466 -0.0274 0.1174 0.1037 0.0284 0.0044 -0.0063 -0.0170 0.0417 0.0120 0.0054 -0.1234 -0.0518 0.0995 -0.1598 0.1998 0.2502 -0.0717 0.0265 -0.0040 0.0372 -0.0200 0.1153 0.1660 -0.0148 -0.0381 0.0762 -0.0781 -0.0884 -0.0766 0.1051 -0.0652 -0.7268 0.4887 -0.1201 -0.0254 0.0005 0.0063 0.2040 0.0684 0.0004 0.1339 -0.0001 0.1110 0.3239 0.0415 -0.0503 0.0443 0.0016 0.0065 -0.3519 0.0169 0.0049 -0.0020 0.5691 0.0851 0.0904 -0.0765 -0.0588 -0.0581 -0.0147 0.0223 0.1649 0.0378 0.0021 0.0186 0.0903 0.0650 0.0016 0.1353 0.1669 -0.0446 -0.0039 0.0030 -0.1925 -0.0078 -0.4201 0.0372 -0.0483 0.0201 0.0535 -0.3563\n",
            "и -0.0312 -0.0627 0.0326 -0.1011 -0.1116 0.0026 -0.0074 0.0816 0.0059 -0.0264 -0.0007 0.3464 -0.0191 -0.0940 0.0732 0.0214 0.0121 -0.0765 0.1064 -0.0412 -0.0244 0.0385 -0.0555 0.0093 0.0683 0.0651 -0.0693 0.0011 -0.0293 -0.1269 0.0157 0.0154 0.0212 -0.0252 0.0794 0.0282 0.2452 -1.3073 -0.1538 -0.0466 0.0382 0.0841 0.0143 -0.1967 -0.1118 -0.0312 -0.1095 0.1742 -0.1011 -0.1492 -0.0043 0.0817 0.0548 -0.0625 -0.0001 -0.1362 0.0278 -0.2779 -0.0431 0.0420 -0.1609 0.0281 -0.0111 0.2021 -0.0444 0.1342 0.0740 0.0817 0.0065 -0.0037 0.1301 -0.1072 0.0289 0.0712 0.0586 -0.0189 -0.0563 0.0127 0.0523 -0.0480 0.0107 -0.0425 -0.2275 -0.0747 0.0998 -0.1358 0.1949 -0.0602 -0.1434 0.0277 0.0299 -0.0882 -0.1580 0.1560 0.1595 0.0469 0.0494 0.0318 -0.1870 0.0452 -0.0510 0.1230 0.0519 -0.0313 0.0520 -0.0466 0.1202 0.0730 0.0274 -0.0139 -0.0955 0.0872 -0.1418 -0.0567 0.0062 -0.0100 -0.1130 0.0364 -0.0202 0.1224 0.1075 -0.0022 0.0363 -0.0096 -0.0446 -0.0053 0.0951 0.0393 -0.1012 -0.1209 0.0646 0.0286 0.0196 -0.0835 -0.0361 -0.0563 0.0434 -0.0514 0.0967 0.0631 -0.0972 -0.0050 -0.1212 0.1060 0.0744 0.1190 0.3668 0.1058 -0.1240 -0.0058 -0.2316 0.1042 0.1937 0.0958 -0.0088 -0.0173 -0.0508 0.1476 -0.0638 -0.0635 0.0178 -0.1187 0.0258 0.0897 -0.0749 0.1428 0.0486 -0.0649 -0.0503 0.0293 0.0302 0.0338 0.0135 -0.0422 -0.0464 -0.0265 -0.0607 -0.0579 0.1152 -0.0413 -0.0540 -0.3885 -0.0080 0.0156 0.0573 0.1157 -0.0090 0.0052 -0.0713 -0.0664 0.0292 0.0135 -0.0118 -0.1085 -0.0074 0.0119 0.0795 -0.0057 0.0464 -0.0027 -0.0397 -0.1157 -0.0995 -0.0391 0.1119 -0.0445 0.0050 0.1388 -0.0471 0.0061 -0.0638 -0.0163 0.0686 0.0169 -0.0818 -0.0590 -0.0275 0.1410 0.0203 -0.1316 -0.1875 -0.0066 0.0102 -0.0300 -0.1029 0.1179 0.0283 -0.0055 0.0708 -0.0304 0.1109 0.1217 0.0600 -0.2107 0.1734 -0.0882 -0.0038 -0.0412 0.0222 -0.0830 0.0290 -0.0258 0.0038 0.0295 0.3608 -0.0562 -0.0493 -0.0832 -0.0236 -0.0415 0.4260 -0.0032 0.1015 -0.0728 -0.2007 0.0433 -0.0117 0.0925 -0.0040 -0.1238 0.0009 0.0608 0.0349 -0.0606 0.1328 0.1421 -0.0633 0.0182 0.1299 -0.1282 0.0372 0.0103 0.3241 0.0395 -0.1535 0.0724 0.0107 0.0025 -0.0619 -0.0141 -0.1246 0.0321 0.0241 0.0708 0.0621 -0.0554 -0.0186 0.0499 -0.0964 -0.1137 -0.0318 -0.0421 0.1938 -0.0291 -0.1300 -0.0910 -0.0139 0.0398 -0.2425 -0.2647\n",
            "в 0.0205 0.0438 0.0254 -0.0753 -0.0597 0.0052 0.0897 0.0013 0.0224 0.0184 -0.2639 -0.3058 -0.1392 -0.0486 -0.0377 0.1188 -0.0257 -0.0005 0.0342 -0.0394 -0.0955 -0.1134 0.0262 -0.0812 0.0015 -0.0004 0.0475 0.0462 -0.0094 -0.0047 0.0482 -0.0797 0.1381 0.0071 -0.1560 0.0159 0.3840 -1.4922 -0.0845 -0.3151 -0.0246 0.2096 0.0347 0.2141 -0.2148 -0.0669 -0.4558 0.0316 -0.5199 -0.1198 -0.0487 -0.0916 -0.0241 0.0341 -0.0437 0.0081 -0.0465 0.3429 -0.2185 0.0107 -0.5323 -0.1441 0.0206 -0.0226 0.0488 -0.0740 0.0759 -0.0880 0.0690 0.0265 0.0467 -0.0061 0.0747 -0.0221 -0.1714 0.0053 0.0087 0.0280 -0.0113 -0.0251 0.0573 0.0053 -0.3269 -0.6911 0.0542 0.2152 -0.2105 0.0455 -0.1315 -0.0079 0.4703 0.0564 0.0182 0.2828 0.1197 -0.0875 -0.1554 -0.0211 -0.1788 0.0151 0.0128 0.4120 -0.0695 -0.0778 -0.0326 0.0372 -0.0275 0.0755 0.2026 0.0439 0.0399 -0.0222 0.1603 0.0498 0.0438 0.0044 0.0191 -0.1155 0.0026 0.0967 0.0953 0.2291 0.3805 -0.0211 -0.1227 0.0027 -0.0509 0.0216 0.0182 0.1655 -0.0520 0.0188 0.0537 -0.0784 0.0067 -0.0410 0.5412 -0.0733 0.2424 0.0490 -0.0556 0.0279 -0.2012 0.0927 0.0242 -0.1510 0.2824 0.6140 -0.0148 0.0214 -0.0185 0.0923 0.0305 -0.0147 -0.0130 0.0172 -0.1141 -0.1205 -0.3192 0.0316 0.0095 0.1194 0.2014 -0.0926 -0.0894 0.1958 -0.0780 0.1824 -0.0135 0.0435 0.0130 0.3028 -0.1030 0.1667 -0.1807 0.1045 -0.1203 0.1103 0.0003 0.0113 0.0521 -0.0038 -0.0391 0.0129 -0.1727 0.0220 -0.0803 -0.0322 0.0162 -0.0802 0.0270 0.0036 -0.0642 -0.1912 0.0376 0.0220 0.0329 -0.0528 -0.0693 -0.0408 -0.0314 0.1356 0.0915 0.0330 -0.0465 -0.0585 0.0908 -0.0864 0.0685 -0.1298 -0.3860 0.0617 0.0718 -0.0525 0.2428 0.0803 0.0518 -0.4289 0.0307 0.2036 0.1017 0.1213 -0.0400 -0.0186 0.1667 0.0823 0.0203 0.0032 -0.0279 0.0114 0.0008 0.5649 -0.0200 -0.0948 -0.0621 -0.1091 0.0544 0.0740 -0.1414 -0.0326 0.0758 0.1105 0.0162 0.0318 0.1360 -0.0124 0.0139 -0.0617 -0.0494 0.0061 -0.4538 0.1954 -0.0442 -0.0608 0.4090 0.0477 0.2640 -0.0479 0.0713 -0.0009 -0.0309 0.1104 0.0139 0.0667 -0.0115 0.2222 0.2994 -0.0430 -0.0036 -0.0263 0.0255 0.0238 0.4151 0.0163 -0.1927 0.0218 0.0935 0.0234 -0.0215 -0.0062 0.0362 0.0256 0.0200 -0.0010 0.0510 0.0456 0.0198 -0.1115 0.1440 -0.0202 -0.0329 0.0063 -0.1953 -0.0150 -0.0316 -0.1002 -0.0077 0.0174 0.3094 0.3463\n",
            "</s> -0.0091 -0.0056 -0.0609 0.0037 0.0415 0.0817 -0.0324 -0.0027 0.0717 -0.0537 0.1597 -0.1093 -0.0730 -0.1000 0.0950 0.0098 -0.0626 0.0235 0.0248 0.0081 0.0685 0.1840 0.0432 -0.0598 -0.0821 -0.0403 -0.0959 0.0180 -0.0317 -0.0608 -0.0926 0.0062 -0.0214 0.1992 0.1649 0.0436 -0.2406 -1.6209 -0.2294 0.0025 0.0479 -0.0385 -0.0249 0.0910 -0.2065 -0.0378 0.0394 -0.0508 -0.2915 -0.0087 -0.1017 -0.2782 -0.0615 -0.0748 0.0867 -0.0987 0.0144 0.2041 -0.5829 -0.0204 -0.9334 0.0492 0.0307 -0.0489 0.0189 0.0120 0.0301 0.0510 0.1144 -0.0603 0.1858 -0.0628 -0.0204 0.0147 0.2152 -0.0412 0.0869 0.0022 0.0293 -0.0519 0.0069 0.4492 0.3079 -0.0350 0.0366 -0.0317 0.2906 0.0530 0.1533 -0.1212 0.2278 -0.0821 0.0471 -0.1901 0.0043 0.0009 0.0480 -0.1263 0.4638 0.0347 -0.0690 0.0291 0.1738 0.0685 -0.0032 -0.0172 -0.4269 0.0134 -0.2756 -0.0758 0.0608 0.1003 0.1271 0.0001 -0.0393 -0.0346 0.0758 0.0527 0.0229 0.0316 0.1757 0.0721 0.0622 0.0759 -0.0541 -0.0428 0.0165 0.1096 0.0311 -0.2374 -0.0583 0.0488 -0.0426 -0.0719 0.0892 0.0280 -0.2281 -0.1164 -0.2407 -0.0467 0.1100 -0.1042 0.2816 0.1700 -0.5027 0.0854 0.1257 -0.3621 -0.0271 -0.0751 0.1765 -0.0289 1.3015 0.0475 0.0338 -0.0419 -0.0408 -0.0676 -0.2289 0.0080 0.0205 0.1824 0.1464 0.0147 -0.1079 -0.1273 0.0402 0.0147 -0.1206 -0.0339 -0.0354 0.1101 -0.0762 -0.1694 -0.4450 0.1117 -0.0306 -0.1415 0.0030 0.0586 -0.0158 -0.1188 0.0390 0.0269 -0.2975 -0.0196 0.0580 0.0412 0.0563 0.0407 -0.0147 0.0390 -0.0438 0.1656 -0.0457 0.0051 -0.1484 0.0461 -0.1131 0.0134 -0.1318 -0.2270 -0.1841 0.0034 0.0969 0.0132 -0.0154 -0.0292 -0.0852 0.0958 -0.0483 -0.0219 0.0136 -0.1263 -0.2458 -0.0316 -0.1014 -0.2205 -0.0452 0.0027 0.0872 -0.0030 -0.0803 0.0098 -0.1019 0.0160 0.0368 0.0350 -0.0544 -0.0762 0.0490 0.1960 -0.0072 0.1328 0.0497 -0.0246 0.0686 -0.0059 0.1083 0.0066 0.0938 0.2794 -0.0470 0.0115 0.2485 -0.0056 0.0450 0.0475 0.0851 -0.1096 -0.2745 0.4771 -0.0205 -0.2552 0.0091 0.0611 0.0830 -0.0710 -0.0250 -0.0811 -0.0245 0.2277 -0.1376 0.1756 -0.2864 0.0415 -0.0093 0.0501 -0.0432 0.0099 0.1080 -0.0019 0.9151 -0.0049 -0.0925 -0.0521 0.0271 0.0453 -0.0645 0.0481 0.1974 0.0343 -0.0778 0.0014 -0.0154 -0.0495 0.0086 0.1865 0.1525 -0.0517 -0.0504 0.0631 -0.4747 -0.1752 -0.3351 0.0864 -0.0177 -0.0826 0.0682 -0.4230\n",
            ": 0.0029 0.1820 -0.0864 0.1102 0.1561 0.0345 -0.0086 0.0762 0.0843 0.1621 0.1122 -0.0688 -0.0871 -0.0675 0.0667 0.0174 -0.0236 -0.0149 0.0969 -0.0288 -0.0254 0.3872 -0.0960 0.0457 -0.1525 0.0007 -0.1837 0.1878 -0.0086 0.0168 -0.1176 -0.0055 -0.0087 -0.0035 0.2950 0.0867 -0.3144 -1.0674 -0.1050 0.1098 -0.1078 0.0688 0.0873 -0.1120 -0.2117 0.1081 0.2872 0.0189 0.0380 0.0822 -0.1246 0.1492 0.0342 -0.2329 0.0389 -0.0137 0.1149 -0.0073 -0.3029 0.0755 -0.5232 -0.2657 0.0751 -0.0285 -0.0196 -0.0581 0.0566 -0.0621 -0.1211 -0.0332 0.1629 -0.0384 -0.1372 -0.0444 -0.3372 -0.0911 -0.1234 0.0438 -0.0515 -0.0830 -0.1208 0.2731 0.2571 0.1231 -0.0232 -0.1757 0.0504 0.0412 0.1240 -0.0390 0.1949 -0.1307 0.1282 -0.2060 0.1364 -0.0990 -0.0944 -0.0244 0.3328 -0.0482 -0.0267 0.0580 0.0721 0.1059 0.0079 -0.0060 0.0152 0.0481 -0.0834 -0.0181 0.1706 0.1388 0.0128 -0.0213 0.1088 0.0574 0.1594 0.1181 -0.1266 -0.0235 0.1000 0.1712 0.0263 0.0421 0.0673 -0.0309 -0.0681 0.2579 -0.0982 0.3228 -0.0471 0.0229 -0.0815 0.0828 -0.0738 0.0427 -0.1056 -0.1698 -0.0413 0.0066 0.0679 -0.1025 0.0455 -0.0545 -0.1709 0.0535 -0.2640 0.4555 -0.0581 -0.0135 0.0074 0.0152 0.0301 -0.0587 0.0277 -0.1047 -0.0932 -0.0805 0.1849 0.1122 -0.0323 -0.0528 0.1298 -0.1723 0.1002 -0.0020 0.0486 0.0190 -0.1819 0.0626 -0.1046 -0.2801 -0.0349 -0.2247 -0.0307 -0.0674 0.0267 -0.1508 -0.0724 0.1777 -0.0868 -0.4265 0.1000 0.0618 0.0670 -0.1407 0.1423 0.0511 0.1003 0.1436 -0.0286 0.0910 -0.1402 0.1080 -0.0709 -0.0176 0.0270 -0.2290 -0.1114 0.1224 -0.0956 -0.1862 0.0897 0.0674 -0.0686 0.0227 0.0690 0.1306 -0.0476 -0.0416 0.0478 0.1904 0.0439 0.0353 -0.0459 0.0692 -0.0001 -0.0852 -0.0222 -0.3515 -0.0855 0.1997 -0.0537 0.0189 -0.0717 -0.0015 0.0678 -0.0824 -0.0271 -0.0678 0.0276 0.1765 -0.0764 -0.0288 0.3381 -0.1010 0.0956 0.0908 -0.0284 -0.0319 0.0816 0.0822 0.0957 0.1025 -0.2292 0.1084 0.1898 -0.0470 -0.0291 -0.0694 -0.4788 0.2269 0.0956 -0.2647 0.0220 0.0428 0.1751 0.1837 0.0262 0.1868 0.0284 -0.2890 -0.1363 0.2278 -0.1769 -0.0008 0.2809 0.0070 -0.1402 -0.0729 0.0983 0.0641 0.5908 -0.0815 -0.0322 -0.0865 -0.0219 -0.0461 -0.0815 -0.0629 0.4690 0.1164 0.0654 -0.1070 -0.0098 0.0537 -0.1412 0.0705 0.0499 -0.0758 -0.0885 0.0272 -0.0302 -0.0779 0.0297 0.0724 0.0319 -0.1318 -0.1433 0.4771\n",
            ") -0.0360 -0.0532 -0.1163 -0.0792 -0.0381 -0.0063 0.1050 -0.0517 -0.0389 0.0794 -0.0032 -0.0236 -0.1259 0.1596 -0.0042 0.0945 0.0727 -0.1040 -0.0767 0.0614 -0.1545 -0.0720 -0.0752 0.0705 -0.1469 -0.3258 -0.0508 0.1804 0.1612 0.0559 -0.0548 -0.0243 -0.1600 0.0851 0.0476 0.0226 -0.1008 -1.0922 0.1391 -0.0299 -0.0194 -0.0069 0.0823 0.0792 -0.0657 0.0236 0.0143 0.1471 0.0891 -0.0289 -0.0753 -0.1915 0.0596 -0.1404 -0.0527 0.0077 0.0250 -0.0676 -0.2314 0.0877 -0.4666 -0.1488 0.0571 -0.0951 -0.2411 0.0289 -0.0062 0.2093 -0.0578 0.0987 -0.0676 0.0783 0.1078 -0.0408 0.1008 0.0223 -0.1743 -0.1380 -0.0461 0.1105 0.0801 0.1439 0.1930 0.0336 0.0742 0.0161 0.2648 0.0778 0.1188 -0.1395 -0.0627 -0.0193 0.0418 -0.1110 -0.1394 0.0162 -0.0090 0.1221 0.0962 -0.0841 -0.1041 -0.1896 0.0117 0.0314 0.1869 0.0574 -0.3451 -0.0979 -0.0720 -0.1007 0.0771 0.0531 0.0297 -0.0413 -0.0418 0.1913 -0.0226 -0.0579 -0.0588 0.1548 0.2902 -0.1380 -0.0667 0.0514 -0.0493 -0.1276 0.0681 0.1049 -0.0733 -0.0843 0.1080 -0.1158 0.0457 0.0811 0.0405 -0.1083 -0.1156 0.1105 0.0157 -0.1609 0.1479 -0.0817 0.0795 0.2997 0.0409 0.0786 0.1203 0.2656 0.0560 0.2680 0.1209 -0.2280 0.2401 -0.0997 0.1241 -0.0431 0.0002 0.0581 -0.0267 0.0468 0.0384 0.0321 -0.0131 0.0861 0.0254 0.0945 0.1743 -0.0612 0.1503 0.1726 -0.0270 -0.0563 0.0754 -0.2182 -0.4576 0.0525 0.1226 -0.0815 -0.1119 -0.0447 -0.2156 -0.2069 0.1678 -0.0227 0.0655 -0.0718 -0.0111 -0.0272 -0.0079 0.0033 0.0244 -0.0797 0.2035 0.0593 0.0992 -0.0660 0.0437 0.0478 -0.0450 0.0171 -0.1673 -0.1225 0.0096 -0.0185 0.0170 0.2590 0.1281 0.0554 0.1643 -0.0652 -0.0570 0.0083 -0.1548 -0.0165 -0.4765 0.1770 -0.1293 -0.0646 -0.0903 -0.0012 -0.1168 -0.0950 0.0609 -0.0450 -0.0003 -0.0891 -0.1005 0.1728 0.1502 0.1068 0.0475 0.3193 -0.0366 0.0774 -0.0100 -0.0413 0.0497 -0.0062 0.0355 0.0692 0.0539 -0.0594 0.1351 0.0730 0.0399 -0.0510 0.0297 0.1589 0.0472 -0.0721 -0.4573 0.3757 -0.0992 -0.1154 -0.0290 0.0617 0.0148 -0.1274 0.0841 0.2643 0.1042 0.0313 -0.0465 -0.0701 -0.1222 -0.0107 -0.1948 0.1459 -0.2057 0.1377 0.2122 0.0883 0.4904 -0.0444 0.1075 -0.0458 0.0176 0.0708 0.0255 -0.0987 0.3319 0.0019 -0.0564 0.1717 -0.0823 -0.0931 -0.1308 0.0056 0.1083 -0.0396 0.0583 -0.0191 -0.3040 -0.1530 0.2314 0.0866 -0.0410 0.1791 -0.1374 -0.2047\n",
            "( -0.0229 -0.0933 -0.1353 -0.0020 -0.0282 0.0397 0.1361 -0.0431 0.0035 0.0426 -0.0767 0.1567 -0.1792 0.0973 0.0017 0.1167 0.0838 -0.1342 -0.0328 0.0354 -0.1723 0.2372 -0.0642 0.0257 -0.1355 -0.2890 -0.0702 0.0995 0.1586 0.0417 -0.1239 -0.0030 -0.1524 -0.0155 0.0724 -0.0035 -0.0427 -1.2914 -0.2210 0.0344 -0.0217 0.1387 0.1262 -0.0275 -0.1585 -0.0634 -0.0383 0.1460 -0.2002 -0.0092 -0.1037 0.1148 0.0269 -0.1806 -0.0397 0.0125 -0.0370 0.0341 -0.2034 0.0326 -0.4140 -0.1728 0.0470 0.0253 -0.1809 0.1292 -0.0493 0.1429 -0.0264 0.0926 -0.0105 0.0693 0.1249 0.0215 -0.0805 0.0311 -0.1277 -0.1387 -0.0261 0.0869 0.0750 0.2889 0.0719 -0.2826 0.0515 -0.1179 0.1200 0.0987 0.1803 -0.1603 0.2524 -0.0542 0.1095 -0.1507 -0.1193 -0.0226 -0.0033 0.0810 0.1444 -0.1095 -0.1106 0.0106 0.2817 0.0462 0.1632 0.0542 -0.0881 -0.1324 -0.0940 -0.1189 0.1099 0.0753 0.0011 -0.0184 -0.0272 0.1700 -0.0095 -0.1174 -0.0665 0.1173 0.3103 -0.1467 -0.1151 0.0453 -0.0725 -0.1154 0.0551 0.1344 -0.0304 -0.1029 0.0483 -0.1096 0.0104 0.0457 0.0624 -0.1402 0.0330 0.0615 -0.0491 -0.1543 0.1578 -0.1020 0.0533 0.2887 -0.2875 0.0880 0.4385 0.3672 0.0869 0.2195 0.0834 -0.1855 -0.1297 -0.0825 0.1237 -0.0071 -0.1483 0.0170 -0.1157 0.0762 0.0142 -0.3205 0.1019 -0.0688 -0.0603 0.0434 0.2109 -0.1334 0.1046 0.1351 -0.0349 -0.2590 0.0926 -0.1487 -0.1282 0.0967 0.1210 0.0036 -0.1930 -0.0749 -0.1703 -0.3483 0.1870 -0.0577 -0.0533 -0.0810 0.0073 -0.0185 0.0050 0.0335 0.0148 -0.0304 0.2223 0.0162 0.0124 -0.0498 0.0903 0.0162 -0.0717 0.0334 -0.1725 0.1130 0.1006 -0.0392 0.0075 0.2553 0.1087 0.0876 0.1361 -0.0639 0.0662 0.0356 -0.1072 -0.0877 -0.1020 0.1137 -0.0890 -0.2908 -0.0070 -0.1127 -0.2469 -0.0978 0.0406 -0.0456 0.0731 -0.0850 -0.0653 0.1526 0.1202 0.2282 -0.0116 0.0253 -0.1401 0.0093 -0.0045 0.0291 0.0658 0.0336 0.0346 0.0405 0.0627 0.0007 0.0642 0.0392 -0.0613 -0.0026 0.0638 0.1707 0.0619 -0.0614 -0.2435 0.2359 -0.1202 -0.1011 -0.0708 0.0400 0.2212 -0.1188 0.1124 0.3207 0.1231 -0.0439 -0.0715 -0.0225 -0.1234 -0.0530 -0.1265 0.1317 -0.1347 0.1568 0.2440 0.0668 0.4225 -0.0075 0.0909 -0.0925 0.0595 0.0354 -0.0377 -0.0518 0.1666 -0.0091 -0.0509 0.1659 -0.0994 -0.1488 -0.0887 -0.1744 0.1375 -0.0399 0.0170 0.0320 -0.0805 -0.1074 0.3065 0.0430 -0.0927 0.2373 -0.0989 -0.0687\n",
            "на -0.0235 -0.0678 0.0607 0.0691 0.0260 0.0418 -0.1359 -0.0059 0.0072 0.0028 -0.3882 -0.2952 0.1072 0.0414 0.0283 -0.1245 -0.0827 -0.1373 0.0082 -0.0471 -0.0016 0.1663 0.0154 -0.0762 0.0619 0.0051 -0.0037 -0.0512 0.1541 -0.0057 -0.2705 -0.0297 0.0440 -0.0472 -0.4249 -0.0391 -0.2491 -1.5903 -0.0008 0.2984 -0.0112 0.0800 -0.0444 -0.5109 0.1440 0.0249 0.0345 0.0109 -0.3660 -0.0721 0.0993 -0.2039 0.0921 -0.0081 0.1047 0.0200 -0.2145 0.0064 -0.1646 0.0747 -0.6302 -0.1842 -0.0037 -0.2668 0.0693 -0.0383 0.0197 -0.2374 -0.0722 -0.0258 0.0501 -0.0103 -0.0406 -0.0251 -0.1127 0.0930 0.0409 0.0078 0.0073 -0.0042 -0.0733 0.1412 -0.2651 -0.6057 0.0442 0.1002 -0.1546 -0.0153 0.5429 0.0814 0.4627 -0.0097 -0.0207 0.4136 0.1548 0.0229 -0.0050 -0.0239 0.1282 0.2563 0.0106 0.4235 0.1085 0.0627 -0.0367 -0.0104 0.1706 0.0876 0.3766 0.0093 0.1701 0.2531 0.1239 -0.0753 -0.0986 0.0012 -0.0131 0.2169 0.0961 -0.0086 0.0157 -0.0949 0.1780 -0.0175 0.0267 -0.0009 -0.0837 -0.0543 -0.0179 -0.1147 0.0030 0.0044 -0.0040 -0.0769 0.0578 0.0542 0.7518 0.0719 0.1751 0.0218 -0.1212 -0.0700 -0.0737 0.0415 0.0057 0.0217 0.2157 0.7238 0.2097 -0.0524 -0.1687 0.0875 0.0461 -0.0388 0.0301 0.0975 -0.5587 -0.1116 -0.1119 0.0198 0.0372 0.4153 0.1672 0.0744 -0.0761 -0.1807 0.1640 0.2769 -0.0390 0.0130 0.1328 0.4447 -0.0606 0.0730 -0.0762 0.0426 0.0218 0.0045 -0.0660 -0.0437 -0.0537 -0.1045 0.0318 0.0366 0.0861 -0.0065 0.0773 0.0442 0.1371 -0.1183 -0.0072 0.0216 0.0552 -0.0750 -0.0008 -0.0968 0.0936 -0.1755 -0.0628 -0.1408 -0.0587 0.4654 -0.4432 0.0459 0.0326 0.0016 0.0025 0.1415 -0.1134 0.2986 0.5816 0.0582 -0.0512 0.2204 0.2558 -0.1368 -0.0121 0.1209 -0.0572 0.3835 0.1009 -0.0648 0.0171 0.0005 -0.0889 -0.0196 -0.1124 0.0789 -0.0248 0.0036 -0.0102 0.1509 -0.1713 -0.1454 0.0599 -0.0866 0.1129 -0.0100 -0.0505 -0.0187 0.0783 0.4517 0.0267 -0.0534 -0.2795 -0.1075 0.0921 -0.0539 -0.0368 -0.0068 -0.4502 0.0988 0.0447 -0.1236 0.2976 -0.0039 0.0848 0.0340 0.0013 -0.1494 0.0126 -0.3273 -0.0901 -0.0539 -0.1606 0.3090 -0.3546 0.0727 0.4283 -0.1377 0.0605 0.1150 0.4260 -0.0055 -0.0691 -0.0105 -0.0031 0.0575 0.0561 0.0132 0.1150 -0.0708 -0.0980 -0.0344 0.0394 0.0276 0.0777 -0.1731 -0.3048 0.1714 -0.0838 -0.0123 -0.2091 -0.0496 -0.0669 -0.0316 -0.0144 0.1063 -0.2394 0.3428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IAs6pUzUHBy4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}